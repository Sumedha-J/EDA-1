{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSOCIATION ANALYSIS WITH APRIORI\n",
    "\n",
    "**File:** Apriori.ipynb\n",
    "\n",
    "**Course:** Data Science Foundations: Data Mining in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSTALL AND IMPORT LIBRARIES\n",
    "\n",
    "The Python library `apyori` contains the implementation of the Apriori algorithm, which can be installed with Python's `pip` command. This command only needs to be done once per machine.\n",
    "\n",
    "The standard, shorter approach may work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install apyori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above command didn't work, it may be necessary to be more explicit, in which case you could run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install apyori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once `apyori` is installed, then load the libraries below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd              # For dataframes\n",
    "import matplotlib.pyplot as plt  # For plotting data\n",
    "from apyori import apriori       # For Apriori algorithm\n",
    "from mlxtend.frequent_patterns import apriori, association_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD AND PREPARE DATA\n",
    "\n",
    "For this demonstration, we'll use the dataset `Groceries.csv`, which comes from the R package `arules` and is saved as a CSV file. The data is in transactional format (as opposed to tabular format), which means that each row is a list of items purchased together and that the items may be in different order. There are 32 columns in each row, each column either contains a purchased items or `NaN`.\n",
    "\n",
    "The code below opens the dataset and converts to to list format, which is necessary for the `apriori()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-10-01 00:02:32-28705-123.2.191.66</td>\n",
       "      <td>[The Perfect Tee, Hotter Than Ever Tee, All-Ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-01 00:10:50-11645-49.191.2.51</td>\n",
       "      <td>[The Diana One-Piece, Womens Havana Dress, Wom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-10-01 00:19:18-40598-110.150.216.111</td>\n",
       "      <td>[Brynn Flats, Georgie Slides]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-10-01 00:20:42-39355-60.242.62.12</td>\n",
       "      <td>[Go Step Lite - Origin, Lorne Sandals]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-10-01 00:21:47-43069-146.23.201.247</td>\n",
       "      <td>[Everyday Train Graphic Tights, All Eyes On Me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-10-01 00:22:21-35489-49.199.120.131</td>\n",
       "      <td>[Haven Sheer Shift Ruffle Dress, Nikita Shift ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-10-01 00:22:34-11273-122.58.117.133</td>\n",
       "      <td>[Inlay Case for iPhone 6/6S Plus - Beverly Hil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-10-01 00:22:48-7208-175.33.160.56</td>\n",
       "      <td>[Rally Roll Neck Knit, Vanessa Embroidered Kni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-10-01 00:25:10-26702-124.190.27.210</td>\n",
       "      <td>[Dimension Frill Wrap Dress  , Anahi Embroider...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017-10-01 00:26:05-29606-49.195.203.89</td>\n",
       "      <td>[Satin Twill Midi Skirt, Desi Floral Full Skir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    order_id  \\\n",
       "0     2017-10-01 00:02:32-28705-123.2.191.66   \n",
       "1      2017-10-01 00:10:50-11645-49.191.2.51   \n",
       "2  2017-10-01 00:19:18-40598-110.150.216.111   \n",
       "3     2017-10-01 00:20:42-39355-60.242.62.12   \n",
       "4   2017-10-01 00:21:47-43069-146.23.201.247   \n",
       "5   2017-10-01 00:22:21-35489-49.199.120.131   \n",
       "6   2017-10-01 00:22:34-11273-122.58.117.133   \n",
       "7     2017-10-01 00:22:48-7208-175.33.160.56   \n",
       "8   2017-10-01 00:25:10-26702-124.190.27.210   \n",
       "9    2017-10-01 00:26:05-29606-49.195.203.89   \n",
       "\n",
       "                                            products  \n",
       "0  [The Perfect Tee, Hotter Than Ever Tee, All-Ov...  \n",
       "1  [The Diana One-Piece, Womens Havana Dress, Wom...  \n",
       "2                      [Brynn Flats, Georgie Slides]  \n",
       "3             [Go Step Lite - Origin, Lorne Sandals]  \n",
       "4  [Everyday Train Graphic Tights, All Eyes On Me...  \n",
       "5  [Haven Sheer Shift Ruffle Dress, Nikita Shift ...  \n",
       "6  [Inlay Case for iPhone 6/6S Plus - Beverly Hil...  \n",
       "7  [Rally Roll Neck Knit, Vanessa Embroidered Kni...  \n",
       "8  [Dimension Frill Wrap Dress  , Anahi Embroider...  \n",
       "9  [Satin Twill Midi Skirt, Desi Floral Full Skir...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/Users/sumedhajauhari/Desktop/My Study Material/Product_Details_apriori.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df_grouped = df.groupby('order_id')['Product_Name'].apply(list)\n",
    "df_grouped = df_grouped[df_grouped.apply(len) > 1]\n",
    "df_grouped = df_grouped.reset_index() #\n",
    "df_grouped.columns = ['order_id', 'products']\n",
    "df_grouped.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23597 entries, 0 to 23596\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   order_id  23597 non-null  object\n",
      " 1   products  23597 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 368.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_grouped.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPLY APRIORI\n",
    "\n",
    "Call `apriori()`. As parameters `apriori()` can take the minimum support, minimum confidence, minimum lift and minimum items in a transaction. Only the pairs of items that satisfy these criteria would be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sumedhajauhari/anaconda3/lib/python3.11/site-packages/mlxtend/frequent_patterns/fpcommon.py:109: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Ensure product lists are unique\n",
    "df_grouped['products'] = df_grouped['products'].apply(lambda x: list(set(x)))\n",
    "\n",
    "# Step 2: Prepare the data for the Apriori algorithm\n",
    "# One-hot encode the product lists\n",
    "encoded_data = df_grouped['products'].apply(lambda x: pd.Series(1, index=x)).fillna(0)\n",
    "\n",
    "# Ensure the columns are unique to avoid reindexing issues\n",
    "encoded_data = encoded_data.loc[:, ~encoded_data.columns.duplicated()]\n",
    "\n",
    "# Display the encoded data to ensure it's correct\n",
    "#print(\"Encoded Data:\")\n",
    "#display(encoded_data)\n",
    "\n",
    "# Step 3: Apply the Apriori algorithm to find frequent itemsets\n",
    "# Further lower the min_support value to capture more itemsets\n",
    "frequent_itemsets = apriori(encoded_data, min_support=0.0005, use_colnames=True)\n",
    "\n",
    "# Display the frequent itemsets\n",
    "print(\"Frequent Itemsets:\")\n",
    "display(frequent_itemsets)\n",
    "\n",
    "# Check if frequent itemsets were found\n",
    "if frequent_itemsets.empty:\n",
    "    print(\"No frequent itemsets found.\")\n",
    "else:\n",
    "    # Step 4: Derive association rules from the frequent itemsets\n",
    "    rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "    \n",
    "    # Display the initial set of rules\n",
    "    print(\"Association Rules:\")\n",
    "    display(rules)\n",
    "    \n",
    "    # Filter rules by confidence and lift\n",
    "    filtered_rules = rules[(rules['confidence'] >= 0.001) & (rules['lift'] >= 0.2)]\n",
    "    \n",
    "    # Display the filtered rules\n",
    "    print(\"Filtered Association Rules:\")\n",
    "    display(filtered_rules)\n",
    "    \n",
    "    # Extract product affinities\n",
    "    product_affinities = []\n",
    "    for _, row in filtered_rules.iterrows():\n",
    "        for product in row['antecedents']:\n",
    "            for related_product in row['consequents']:\n",
    "                product_affinities.append({\n",
    "                    'product': product, \n",
    "                    'related_product': related_product, \n",
    "                    'support': row['support'], \n",
    "                    'confidence': row['confidence'], \n",
    "                    'lift': row['lift']\n",
    "                })\n",
    "    \n",
    "    # Convert to DataFrame and display\n",
    "    affinities_df = pd.DataFrame(product_affinities)\n",
    "    print(\"Product Affinities:\")\n",
    "    display(affinities_df)\n",
    "\n",
    "    \"\"\"\n",
    "    # Prepare the final output at order_id, product level\n",
    "    # Create a DataFrame with order_id and the products involved in frequent itemsets\n",
    "    order_product_affinity = []\n",
    "    for index, row in df_grouped.iterrows():\n",
    "        for product in row['products']:\n",
    "            if any(set([product]) <= set(itemset) for itemset in frequent_itemsets['itemsets']):\n",
    "                order_product_affinity.append({'order_id': row['order_id'], 'product': product})\n",
    "\n",
    "    # Convert to DataFrame and set the column names\n",
    "    final_df = pd.DataFrame(order_product_affinity, columns=['order_id', 'product'])\n",
    "\n",
    "    # Display the final DataFrame\n",
    "    print(final_df)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
